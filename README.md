# HEPML
**Machine Learning tool for the DESY-CBPF-UERJ collaboration**

Quick start
-----------

Inside your private area (NOT in the eos or dust area and NOT inside a CMSSW release), download the code.  
```bash
git clone https://github.com/DESY-CBPF-UERJ/ANAML.git
```

Source the hepenv environment before work with the HEPML:
```
hepenv
```

Enter in the HEPML directory:  
```bash
cd HEPML
```

Know how many models(jobs) the code is setted to train (information needed to submit jobs):  
```bash
python train.py -j -1
```

Train the model in the position **n** of the list for the signal **signal_name**:  
```bash
python train.py -j n -s signal_name
```
Ex.:
```bash
python train.py -j 2 -s Signal_1000_100
```

Submit condor jobs:  
1. Make **submit_jobs.sh** an executable:  
`chmod +x submit_jobs.sh`   
2. See all flavours available for the jobs:  
```bash
./submit_jobs.sh help
```  
3. Submit all the **N** jobs the code is setted to train:  
```bash
./submit_jobs.sh flavour N signal_name
```  

After the jobs have finished, evaluate the training results:
```bash
python evaluate.py -s selection_name -p period
```
Ex.:
```bash
python evaluate.py -s ML -p 17
```
period = APV_16, 16, 17, or 18


General information
-----------

* This code is meant to be used in association with the HEPAnalysis framework.

* The training setup is made in the beginnig of the file **train.py**.

* The code reads the data stored inside the **<output_path>/datasets** folder created by the tool **grouper.py** of the HEPAnalysis framework.

* The training results and files are stored in **<output_path>/datasets/<period>/ML/<signal_name>/**
